@article{lme4,
    title = {Fitting Linear Mixed-Effects Models Using {lme4}},
    author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and
      Steve Walker},
    journal = {Journal of Statistical Software},
    year = {2015},
    volume = {67},
    number = {1},
    pages = {1--48},
    doi = {10.18637/jss.v067.i01},
}

@article{BenjaminiHochberg1995,
   author = {Benjamini, Y., & Hochberg, Y.},
   title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
   journal = {Journal of the Royal Statistical Society: Series B},
   volume = {57},
   issue  = {1},
   pages = {289-300},
   year = {1995}
}
@article{BenjaminiYekutieli2001,
   author = {Benjamin, Y., & Yekutieli. D. },
   title = {The Control of the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing under Dependency},
   journal = {Annals of Statistics},
   volume = {29},
   pages = {1165-1188},
   year = {2001}
}


@article{RN33089,
   author = {Bang, H., Jung, S., & George, S.L.},
   title = {Sample Size Calculation for Simulation-based Mulitple-testing Procedures},
   journal = {Journal of Biopharmaceutical Statistics},
   volume = {15},
   pages = {957-967},
   year = {2005},
   type = {Journal Article}
}

@article{Berger1982,
   author = {Berger, Roger L.},
   title = {Multiparameter Hypothesis Testing and Acceptance Sampling},
   journal = {Technometrics},
   volume = {24},
   number = {4},
   pages = {295-300},
   year = {1982},
   type = {Journal Article}
}

@article{Berger1996,
   author = {Berger, Roger L. and Hsu, Jason C.},
   title = {Bioequivalence Trials, Intersection–Union Tests and Equivalence Confidence Sets},
   journal = {Statistical Science},
   volume = {11},
   number = {4},
   pages = {283-319},
   year = {1996},
   type = {Journal Article}
}

@misc{RN27978,
   author = {Bloom, Howard S.},
   title = {The Core Analytics of Randomized Experiments for Social Research},
   publisher = {MDRC},
   year = {2006},
   type = {Government Document}
}

@techreport{RN33091,
   author = {Bretz, F, . Hothorn, T., and  Westfall, P. },
   title = {Multiple Comparisons Using R},
   year = {2011},
   type = {Report}
}

@article{RN23882,
   author = {Chen, J., Luo, J., Liu, K., Mehrotra, D.},
   title = {On Power and Sample Size Computation for Multiple Testing Procedures},
   journal = {Computational Statistics and Data Analysis},
   volume = {55},
   pages = {110-122},
   year = {2011},
   type = {Journal Article}
}

@article{Deng2008,
   author = {Deng, Xutao and Xu, Jun and Wang, Charles},
   title = {Improving the Power for Detecting Overlapping Genes from Multiple DNA Microarray-derived Gene Lists},
   journal = {BMC Bioinformatics},
   volume = {9},
   year = {2008},
   type = {Journal Article}
}

@article{RN4473,
   author = {Dong, Nianbo and Maynard, Rebecca},
   title = {PowerUP!: A Tool for Calculating Minimum Detectable Effect Sizes and Minimum Required Sample Sizes for Experimental and Quasi-Experimental Design Studies},
   journal = {Journal of Research on Educational Effectiveness},
   volume = {6},
   number = {1},
   pages = {24-67},
   ISSN = {1934-5747},
   year = {2013},
   type = {Journal Article}
}

@article{RN23878,
   author = {Dudoit, S., Shaffer, J.P., Boldrick, J.C.},
   title = {Multiple Hypothesis Testing in Microarray Experiments},
   journal = {Statistical Science},
   volume = {18},
   number = {1},
   pages = {71-103},
   year = {2003},
   type = {Journal Article}
}

@article{RN24280,
   author = {Dunn, Olive Jean},
   title = {Estimation of the Medians for Dependent Variables},
   pages = {192-197},
   abstract = {Joint intervals of bounded confidence are suggested for the medians of a bivariate population with continuous marginal distributions. The two intervals are of the classic type based on sample order statistics.},
   ISSN = {0003-4851},
   DOI = {10.1214/aoms/1177706374},
   url = {http://projecteuclid.org/euclid.aoms/1177706374},
   year = {1959},
   type = {Journal Article}
}

@article{RN24281,
   author = {Dunn, Olive Jean},
   title = {Multiple Comparisons among Means},
   journal = {Journal of the American Statistical Association},
   volume = {56},
   number = {293},
   pages = {52-64},
   ISSN = {0162-1459},
   DOI = {10.1080/01621459.1961.10482090},
   url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1961.10482090},
   year = {1961},
   type = {Journal Article}
}


@article{RN33093,
   author = {Ge, Y., Dudoit, S., & Speed, T.P.},
   title = {Resampling-based Multiple Testing for Microarray Data Analsysis},
   journal = {Test},
   volume = {12},
   pages = {1-77},
   year = {2003},
   type = {Journal Article}
}


@techreport{RN30153,
   author = {Hedges, Larry V.  and Rhoads, Christopher},
   title = {Statistical Power Analysis in Education Research},
   institution = {National Center for Special Education Research},
   note = {http://www.eric.ed.gov/ERICWebPortal/contentdelivery/servlet/ERICServlet?accno=ED509387},
   abstract = {This paper provides a guide to calculating statistical power for the complex multilevel designs that are used in most field studies in education research. For multilevel evaluation studies in the field of education, it is important to account for the impact of clustering on the standard errors of estimates of treatment effects. Using ideas from survey research, the paper explains how sample design induces random variation in the quantities observed in a randomized experiment, and how this random variation relates to statistical power. The manner in which statistical power depends upon the values of intraclass correlations, sample sizes at the various levels, the standardized average treatment effect (effect size), the multiple correlation between covariates and the outcome at different levels, and the heterogeneity of treatment effects across sampling units is illustrated. Both hierarchical and randomized block designs are considered. The paper demonstrates that statistical power in complex designs involving clustered sampling can be computed simply from standard power tables using the idea of operational effect sizes: effect sizes multiplied by a design effect that depends on features of the complex experimental design. These concepts are applied to provide methods for computing power for each of the research designs most frequently used in education research. Appendices include: (1) Design Effects in Two- or Three-Level Hierarchical Designs With and Without Covariates; (2) Design Effects in Two- or Three-Level Randomized-Block Designs With and Without Covariates; (3) Computing Power in Three-Level Randomized-Block Designs; (4) Multilevel Models Defining Tests for Treatment Effects; and (5) Glossary of Terms. (Contains 5 footnotes and 2 tables.)},
   keywords = {Research Design
Field Studies
Computers
Effect Size
Correlation
Sampling
Computer Software
Multivariate Analysis
Statistical Analysis
Educational Research},
   url = {http://www.eric.ed.gov/ERICWebPortal/detail?accno=ED509387},
   year = {2010},
   type = {Report}
}

@article{RN24282,
   author = {Holm, S.},
   title = {A Simple Sequentially Rejective Multiple Test Procedure.},
   journal = {Scand. J. Statist.},
   volume = {6},
   number = {2},
   pages = {65-70},
   year = {1979},
   type = {Journal Article}
}

@inbook{RN33095,
   author = {Maurer, W., and Mellein, B.},
   title = {On New Multiple Test Procedures Based on Independent P-values and the Assessment of their Powers},
   booktitle = {Multiple Hypotheses Testing},
   editor = {P. bauer, G. Hommel and E. Sonnermann},
   publisher = {Heidelberg, Springer},
   pages = {48-66},
   year = {1988},
   type = {Book Section}
}

@article{Porter2018,
   author = {Porter, Kristin E.},
   title = {Statistical Power in Evaluations That Investigate Effects on Multiple Outcomes: A Guide for Researchers},
   journal = {Journal of Research on Educational Effectiveness},
   volume = {11},
   issue  = {2},
   pages = {267-295},
   year = {2018},
   type = {Journal Article}
}

@article{RN33097,
   author = {Ramsey, P.H.},
   title = {Power Differences between Pairwise Multiple Comparisons},
   journal = {Journal of American Statistical Association},
   volume = {75},
   pages = {479-487},
   year = {1978},
   type = {Journal Article}
}

@techreport{RN23884,
   author = {Raudenbush, S.W. and Spybrook, J. and Congdon, R. and Liu, X. and Martinez, A. and Bloom, H. and Hill, C},
   title = {Optimal Design Plus Empirical Evidence (Version 3.0)},
   url = {http://wtgrantfoundation.org/resource/optimal-design-with-empirical-information-od},
   year = {2011},
   type = {Report}
}

@techreport{RN23748,
   author = {Schochet, Peter Z.},
   title = {Guidelines for Multiple Testing in Impact Evaluations of Educational Interventions. Final Report},
   institution = {Mathematica Policy Research, Inc. P.O. Box 2393, Princeton, NJ 08543-2393},
   abstract = {Studies that examine the impacts of education interventions on key student, teacher, and school outcomes typically collect data on large samples and on many outcomes. In analyzing these data, researchers typically conduct multiple hypothesis tests to address key impact evaluation questions. Tests are conducted to assess intervention effects for multiple outcomes, for multiple subgroups of schools or individuals, and sometimes across multiple treatment alternatives. Multiple comparisons issues are not frequently addressed in impact evaluations of educational interventions. The Institute of Education Sciences (IES) at the U.S. Department of Education (ED) contracted with Mathematica Policy Research, Inc. (MPR) to develop guidelines for appropriately handling multiple testing in education research. This report provides a structure to address the multiplicity problem and discusses issues to consider when formulating a testing strategy. Four appendixes are included: (1) Panel Members; (2) Introduction to Multiple Testing; (3) Weighting Options for Constructing Composite Domain Outcomes; and (4) Bayesian Hypothesis Testing Framework (alternative to the classical hypothesis testing framework that is assumed for this report.) (Contains 5 footnotes and 5 tables.)},
   url = {http://www.eric.ed.gov/ERICWebPortal/contentdelivery/servlet/ERICServlet?accno=ED502199},
   year = {2008},
   type = {Report}
}

@article{RN23881,
   author = {Senn, Stephen and Bretz, Frank},
   title = {Power and Sample Size when Multiple Endpoints are Considered},
   journal = {Pharmaceutical Statistics},
   volume = {6},
   pages = {161-170},
   DOI = {10.1002/pst.301},
   year = {2007},
   type = {Journal Article}
}

@article{RN352,
   author = {Shaffer, Juliet Popper},
   title = {Multiple Hypothesis Testing},
   journal = {Annual Review of Psychology},
   volume = {46},
   number = {1},
   pages = {561-584},
   note = {Used in 2013 SSC report (Bloom and Unterman 2013)},
   keywords = {Methods},
   ISSN = {0066-4308},
   year = {1995},
   type = {Journal Article}
}

@techreport{RN24179,
   author = {Spybrook, Jessica and Bloom, H.S. and Congdon, Richard and Hill, Carolyn J. and Martinez, Andres and Raudenbush, Stephen W.},
   title = {Optimal Design Plus Empirical Evidence: Documentation for the “Optimal Design” Software Version 3.0.},
   abstract = {The Optimal Design software, developed with support from the National Institute of Mental Health and the William T. Grant Foundation, now contains modules that can assist researchers in planning single level trials, cluster randomized trials, multi-site randomized trials, multi-site-cluster randomized trials, cluster randomized trials with treatment at level three, trials with repeated measures, and cluster randomized trials with repeated measures.},
   url = {http://wtgrantfoundation.org/resource/optimal-design-with-empirical-information-od},
   year = {2011},
   type = {Report}
}

@techreport{RN33098,
   author = {Tukey, J.W.},
   title = {The Problem of Multiple Comparisions},
   institution = {Princeton University},
   year = {1953},
   type = {Report}
}

@book{RN28696,
   author = {Westfall, Peter H and Young, S Stanley},
   title = {Resampling-based Multiple Testing: Examples and Methods for P-value Adjustment},
   publisher = {John Wiley & Sons},
   volume = {279},
   ISBN = {0471557617},
   year = {1993},
   type = {Book}
}

@book{MTSAS,
   author = {Westfall, Peter H, Tobias, R.D. and Wolfinger, R. D.},
   title = {Multiple Comparisons and Multiple Tests using SAS},
   publisher = {The SAS Institute},
   ISBN = {9781607648857, 9781607647836, 9781642955187},
   year = {2011},
   type = {Book}
}

@misc{DNREPORT,
   author = {Corrin W., Sepanik S., Rosen, R., Shane, A.}, 
   title = {Addressing Early Warning Indicators: Interim Impact Findings from the Investing in Innovation (i3) Evaluation of Diplomas Now},
   publisher = {MDRC},
   year = {2016},
   type = {Government Document}
}

@article{GELMANETAL2012,
   author = {Gelman A., Hill J., Yajima M.},
   title = {Why We (Usually) Don't Have to Worry About Multiple Comparisons},
   journal = {Journal of Research on Educational Effectiveness},
   volume = {5},
   pages = {189-211},
   year = {2012},
   type = {Journal Article}
}

@book{GelmanHill2007,
   author = {Gelman A., Hill J., Yajima M.},
   title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
   publisher = {Cambridge University Press},
   year = {2007}
}

@article{MiratrixWeiss2020,
   author = {Miratrix, Luke, Michael Weiss, and Henderson, Brit},
   title = {An Applied Researcher’s Guide to Estimating Effects From Multisite Individually Randomized Trials: Estimands, Estimators, and Estimates},
   journal = {Journal of Research on Educational Effectiveness},
   year = {2020, forthcoming},
}

