Below is a checklist of tasks to complete for finalizing the PUMP project. For each, we can list champion & target date for completion. 

This list is not complete - to be added to and checked off by everyone.

# R package
- Expand models (e.g. D3 designs with ICC non zero, and others discussed) & validate (Kristen, TBD)
    Done this (in particular the ICC stuff) except for additional models, to be postponed.
    TO DO: Add the d1.1_mcc model (simple randomization)
- Run additional validation for extreme values (Kristen, TBD)
    Near done.
- Update with new naming convention (Kristen)
    Done!
- Complete code commenting (Kristen, TBD)
    Done enough.
- Complete all testing (Kristen and Luke, TBD)
    Done enough, will add tests as issues arise.
- Source code completed, ASCII files, with formatted help files and be packaged for easy installation. 
    Still to do.
- Submit package to CRAN - including JSS submission as vignettes in the package. 
- Make sure all functions still work when specifying one outcome (Kristen, TBD)
- Check for cluster RCT (using simulation?) whether correlation between test statistics is still equiv to correlation between outcomes (assuming constant values of R2 across outcomes) (Kristen, TBD)
- Potentially use simulations to estimate rho matrix for users when entering other information about data - corr between outcomes, R2's (Kristen, maybe, TBD)
- Revisit terminology of MDES - should we use "effect size" or "ATE" instead - build into user testing (Kristin, TBD)

## Kristen's todo list
- remove dependency on multtest package
- unit test: no covariates
- unit test: does it work with J = 1? M = 1? K = 1?
- unblocked design
- allow user to give PowerUp names
- document remaining issues with sample size/mdes code, implement correct level of warnings
- write up WY validation
- unit tests for correlated and uncorrelated test statistics for sample size code
- should omega be a vector? check consistencny of all scalar and vector params
- understand unit test with correlated outcomes
- allow user to do no adjustment for sample size, mdes but only for individual power


# Shiny app
- Introduction/education matter (Kristin, 8/31)
- Tabs completed for blocked individual RCT (Zarni, 7/31)
- Tabs built out for additional designs/models (Zarni, 8/31)
- User testing/review complete (Team, 9/15)
- Revisions implemented (Zarni & Kristin, 10/15)
- Submit to Pubs for review (Zarni, 10/15)
- Test on host server (Zarni, 8/31)

# Manuscript
- Revisit outline & assign champions to sections (Team, 7/1)
- Complete draft (Team, 9/30)
- Get reviewer comments (Chuck, 10/15)
- Revised draft (Team, 10/31)

# Video
- Reach out to video staff with plans and questions (Zarni, 7/31)
- Budget video (Kristin, 8/15)

# Presentation
- Kristen presenting

# Next check-in
- champions for paper sections
- planning for SREE presentation - Kristin P will share past slide deck for reference

# Stretch goals
- tool that helps user build a block matrix of correlations based on a list of correlations between outcomes
- tool the helps user determine correlation between test statistics using simulation
- resolve terminology: MDES, ES, ATE_ES, impact?
- additional designs, including: d3.3_2mff, d3.1_m3fc2rr, d2.2_m2cc with cluster robust standard errors
- for sample size, allow a vector of MDES, i.e. combination of zero and nonzero values, and allow for numZero flag
- effect size calculator
- speed up everything
- WY follow up: WY with a small number of schools, large number of permutations, and no effect, do we get the intended power/p-value?  What if we don’t do any adjustment–is it because of divergent/unstable models?

